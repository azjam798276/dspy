---
id: "rollout_20260102_155948_585332_golden"
generated_at: "2026-01-02T17:04:39.592908"
tags: ["devops-engineer", "auto-generated"]
---

## Problem
---
id: "20260102_gpu_time_slicing"
difficulty: "medium"
tags: ["gpu", "nvidia", "time-slicing", "device-plugin", "k8s"]
tech_stack: "NVIDIA GPU Operator, K3s, ConfigMap"
---

# User Story
As a GPU engineer, I want to configure NVIDIA time-slicing on K3s, so multiple VDI sessions can share a single GPU efficiently.

# Context & Constraints
**Time-Slicing Configuration:**
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: time-slicing-config
  namespace: gpu-operator
data:
  any: |-
    version: v1
    flags:
      migStrategy: none
    sharing:
      timeSlicing:
        renameByDefault: false
        failRequestsGreaterThanOne: false
        resources:
        - name: nvidia.com/gpu
          replicas: 8
```

**ClusterPolicy Patch:**
```bash
kubectl patch clusterpolicy/cluster-polic

## Solution
{
  "session_id": "bc4245b7-ed38-41bc-bae3-7b47b2ae4f66",
  "response": "I will generate the JSON output containing the reasoning and the code changes for creating the `manifests/phase-0` directory and the `time-slicing-config.yaml`, `patch-cluster-policy.sh`, and `gpu-validation-pod.yaml` files.\n```json\n{\n  \"reasoning\": \"To configure NVIDIA time-slicing on K3s, I need to define the resource sharing strategy (8 replicas per GPU) in a ConfigMap and instruct the GPU Operator to use it via the ClusterPolicy. I will create a Phase 0 validation manifest set including: 1) The `time-slicing-config` ConfigMap, 2) A script to patch the `ClusterPolicy`, and 3) A validation Pod that requests a single GPU slice (`nvidia.com/gpu: 1`) to verify the configuration.\",\n  \"code_patch\": \"mkdir -p manifests/phase-0\\n\\ncat <<EOF > manifests/phase-0/time-slicing-config.yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: time-slicing-config\\n  namespace: gpu-operator\\ndata:\\n  any: |-\\n    version: v1\\n    flags:\\n      migStrategy: none\\n    sharing:\\n      timeSlicing:\\n        renameByDefault: false\\n        failRequestsGreaterThanOne: false\\n        resources:\\n        - name: nvidia.com/gpu\\n          replicas: 8\\nEOF\\n\\ncat <<EOF > manifests/phase-0/patch-cluster-policy.sh\\n#!/bin/bash\\nkubectl patch clusterpolicy/cluster-policy \\\\\\n  -n gpu-operator --type merge \\\\\\n  -p '{\\\"spec\\\":{\\\"devicePlugin\\\":{\\\"config\\\":{\\\"name\\\":\\\"time-slicing-config\\\"}}}}'\\nEOF\\nchmod +x manifests/phase-0/patch-cluster-policy.sh\\n\\ncat <<EOF > manifests/phase-0/gpu-validation-pod.yaml\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: gpu-validation-pod\\nspec:\\n  containers:\\n  - name: selkies\\n    image: ghcr.io/selkies-project/selkies-gstreamer/gst-web:latest\\n    env:\\n    - name: SELKIES_ENCODER\\n      value: \\\"nvh264enc\\\"\\n    resources:\\n      limits:\\n        nvidia.com/gpu: \\\"1\\\"\\n        memory: \\\"4Gi\\\"\\n      requests:\\n        nvidia.com/gpu: \\\"1\\\"\\n    volumeMounts:\\n    - name: shm\\n      mountPath: /dev/shm\\n  volumes:\\n  - name: shm\\n    emptyDir: { medium: Memory }\\nEOF\"\n}\n```",
  "stats": {
    "models": {
      "gemini-2.5-flash-lite": {
        "api": {
          "totalRequests": 1,
          "totalErrors": 0,
          "totalLatencyMs": 2547
        },
        "tokens": {
          "input": 5953,
          "prompt": 5953,
          "candidates": 79,
          "total": 6399,
          "cached": 0,
          "thoughts": 367,
          "tool": 0
        }
      },
      "gemini-3-pro-preview": {
        "api": {
          "totalRequests": 4,
          "totalErrors": 0,
          "totalLatencyMs": 79836
        },
        "tokens": {
          "input": 70606,
          "prompt": 92482,
          "candidates": 833,
          "total": 97621,
          "cached": 21876,
          "thoughts": 4306,
          "tool": 0
        }
      }
    },
    "tools": {
      "tot

## Key Techniques
- JWT token handling
